{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_11_clustering-published.ipynb) (Este botón no anda, tenemos que ver dónde colgaremos las cosas)\n",
    "$\\renewcommand\\hfrac[2]{\\genfrac{}{}{0pt}{}{#1}{#2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Evaluación de modelos.\n",
    "\n",
    "Este notebook contiene los ejercicios de la primera parte del taller `Evaluación de modelos, series temporales y toma de decisiones` desarrollado para [Escuela Bayes Plurinacional](https://bayesplurinacional.org/) SALTA 2024.\n",
    "\n",
    "**Ejercicios**:\n",
    "- 1.1 Modelo Base vs Modelo Monty Hall\n",
    "    - 1.1.1 Definir sus distribuciones condicionales *a priori*\n",
    "    - 1.1.2 Simular datos con el modelo Monty Hall\n",
    "    - 1.1.3 Calcular la secuencia de predicción que hacen los modelo de los datos\n",
    "    - 1.1.4 Expresar intuitivamente la diferencia de desempeño predictivo de los modelos\n",
    "    - 1.1.5 Calcular la secuencia de actualizaciones de la creencia de los modelos a medida que vamos agregando datos\n",
    "    - 1.1.6 Graficar el resultado de 1.1.4\n",
    "    - 1.1.7 ¿Que ocurriría con la evaluación de modelos si en los datos hubiera al menos una pista sobre la caja cerrada? \n",
    "- 1.2. Modelo AcausaB vs BcausaA\n",
    "- 1.3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1.1: Modelo \"Base\" ($M_0$) vs Modelo \"Monty Hall\" ($M_1$)\n",
    "\n",
    "En la siguiente figura se puede observar la especificación gráfica del modelo \"Monty Hall\" (izquierda) y el modelo \"Base\" (derecha) visto en la presentación. Abajo de ellos se muestra la distribución de creencias *a posteriori* sobre la posición del regalo luego de que hayamos elegido cerrar la caja $1$ y nos mostraran que la caja $2$ no estaba el regalo, $P(r|s=2,c=1)$\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/BayesDeLasProvinciasUnidasDelSur/static/master/curso/2024/MontyHall.png\" alt=\"drawing\" width=\"50%\"/>\n",
    "</center>\n",
    "\n",
    "El modelo Monty Hall supone que la pista $s$ no puede señalar la caja en la que se encuentra el regalo $s\\neq r$ ni la caja que hemos cerrado previamente $s\\neq c$. En cambio, el modelo Base supone que la pista $s$ no puede señalar únicamente a la caja en la que se encuentra el regalo $s\\neq r$, pudiendo señalar cualquiera de las otras dos cajas, sin tener en cuenta si hemos cerrado una de ellas previamente.\n",
    "\n",
    "Quisiéramos actualizar nuestras creencias sobre los modelos causales alternativos luego de observar los datos, $P(\\text{Modelo}|\\text{Datos})$.\n",
    "\n",
    "$$P(\\text{Modelo}|\\text{Datos}) = \\frac{P(\\text{Datos}|\\text{Modelo})P(\\text{Modelo})}{P(\\text{Datos})}$$\n",
    "\n",
    "Debemos calcular:\n",
    "- La predicción que hace el modelo sobre los datos: $P(\\text{Datos}|\\text{Modelo})$\n",
    "- La predicción de los datos realizada con la contribución de todos los modelos: $P(\\text{Datos})$\n",
    "- La creencia previa \"honesta\" sobre los modelos: $P(\\text{Modelo})$\n",
    "\n",
    "Si antes de ver los datos no tenemos preferencia por ninguno de los modelos podemos dividir nuestra creencia en partes iguales.\n",
    "\n",
    "$$P(\\text{Modelo}) = 0.5$$\n",
    "\n",
    "Recordemos que por la regla de la suma (princpio de integridad), la predicción de los datos se realiza con la contribución de todas las hipótesis.\n",
    "\n",
    "$$P(\\text{Datos}) \\overset{\\hfrac{\\text{Regla de}}{\\text{la suma}} }{=} \\sum_{\\text{Modelo}} P(\\text{Modelo},\\text{Datos}) \\overset{\\hfrac{\\text{Regla de}}{\\text{la producto}} }{=} \\sum_{\\text{Modelo}} P(\\text{Datos}|\\text{Modelo}) P(\\text{Modelo})$$\n",
    "\n",
    "Luego, lo único que nos hace falta calcular es la predicción que hace cada uno de los modelos con la contribución de todas sus hipótesis internas.\n",
    "\n",
    "$$P(\\text{Datos} = \\{\\underbrace{c_1, s_1, r_1}_{\\hfrac{\\text{Primer}}{\\text{episodio}}}, \\underbrace{c_2, s_2, r_2}_{\\hfrac{\\text{Segundo}}{\\text{episodio}}},  \\,  \\dots \\, \\underbrace{c_T, s_T, r_T}_{\\hfrac{\\text{T-ésimo}}{\\text{episodio}}}  \\}|\\text{Modelo})$$\n",
    "\n",
    "Un episodio es la secuencias completa de observaciones de todas las variables ocultas de un modelo. Al iniciar un episoidio, todas las variables son ocultas (hipótesis). Al final el episodio, todas son observables. En este ejemplo, vamos a considerar que al interior de un episodio $t$ (con $t \\in \\{1 \\dots T\\}$) las observaciones llegan siempre en el mismo orden: observamos primero la caja que se cierra $c_t$, luego la pista $s_t$ y finalmente la posición del regalo $r_t$. Luego, la predicción que hace un modelo sobre esos datos puede escribirse sel siguiente modo,\n",
    "\n",
    "$$P(\\text{Datos}=\\{c_t,s_t,r_t \\}|Modelo) = P(c_t|Modelo)P(s_t|c_t,Modelo)P(r_t|s_t,c_t,Modelo) $$\n",
    "\n",
    "Como ninguno de los dos modelos vincula los episodios entre sí (ninguno usa los datos de un episodio para predecir lo datos en otro episodio), podemos descomponer la predicción sobre el conjunto de datos sobre todos los episodios como el producto de las predicciones que lo modelos hacen al interior de cada episodio.\n",
    "\n",
    "$$P(\\text{Datos} |\\text{Modelo}) = \\prod_{t\\in \\{1,\\dots,T \\}} P(\\underbrace{c_t, s_t, r_t}_{\\hfrac{\\text{t-ésimo}}{\\text{episodio}}}|\\text{Modelo}) $$\n",
    "\n",
    "Tenemos todo para calcular la probabilidad de los modelos dado los datos. Defimamos primero las distribución condiciones *a priori* honesta de cada uno los modelos.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1.1.1**: Definir sus distribuciones condicionales *a priori*\n",
    "\n",
    "La espcificación gráfica del modelo Base $M_0$ define la distribución conjunta *a priori* sobre las tres hipótesis, $P(r,c,s|M_0)$, como una descomposición entre las siguientes tres probabilidades condicionales.\n",
    "\n",
    "$$P(r,c,s|M_0) = P(r|M_0)P(c|M_0)P(s|r,M_0) $$\n",
    "\n",
    "La espcificación gráfica del modelo Monty Hall $M_1$ define la distribución conjunta *a priori* sobre las tres hipótesis, $P(r,c,s|M_0)$, como una descomposición entre las siguientes tres probabilidades condicionales.\n",
    "\n",
    "$$P(r,c,s|M_1) = P(r|M_0)P(c|M_0)P(s|r,c,M_1) $$\n",
    "\n",
    "Las distribuciones condicionales *a priori* sobre $r$ y $c$ son iguales en ambos modelos.\n",
    "\n",
    "$$\n",
    "P(r|M) = \\begin{array}{c|c|c}\n",
    "  r=1 & r=2 & r=3 \\\\\n",
    "  \\hline\n",
    "  1/3 & 1/3 & 1/3 \\\\\n",
    "\\end{array}\n",
    "\n",
    "\\hspace{2cm}\n",
    "\n",
    "P(c|M) = \\begin{array}{c|c|c}\n",
    "  c=1 & c=2 & c=3 \\\\\n",
    "  \\hline\n",
    "  1/3 & 1/3 & 1/3 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "La única diferencia entre los modelos aparece en la distribución condicional sobre la pista. En el modelo Base solo depende del regalo $r$.\n",
    "\n",
    "$$\n",
    "P(s|r,M_0) = \\begin{array}{c|c|c|c}\n",
    "  & s=1 & s=2 & s=3 \\\\ \\hline\n",
    " r=1 & 0 & 1/2 & 1/2 \\\\ \\hline\n",
    " r=2 & 1/2 & 0 & 1/2 \\\\ \\hline \n",
    " r=3 & 1/2 & 1/2 & 0 \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Y en el modelo Monty Hall depende del regalo $r$ y la caja cerrada $c$. Para simplificar, mostraremos los valores cuando $c=1$.\n",
    "\n",
    "$$\n",
    "P(s|r,c=1,M_0) = \\begin{array}{c|c|c|c}\n",
    "  & s=1 & s=2 & s=3 \\\\ \\hline\n",
    " r=1 & 0 & 1/2 & 1/2 \\\\ \\hline\n",
    " r=2 & 0 & 0 & 1 \\\\ \\hline \n",
    " r=3 & 0 & 1 & 0 \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Notar que cada renglón suma 1, pues cada condicional representa una distribución de probabilidad distinta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# COMPLETAR: Reemplazando signos de pregunta (?)\n",
    "\n",
    "# Probabilidad del regalo\n",
    "pr = [1/3, 1/3, 1/3] # P(r) = pr[r]\n",
    "\n",
    "# Probabilidad de cerrar\n",
    "pc = [1/3, 1/3, 1/3] # P(c) = pc[c]\n",
    "\n",
    "# Probabilidad de la pista modelo Base M0\n",
    "# P(s|r,M0) = ps_rM0[r][s] \n",
    "ps_rM0=[[  0, 1/2, 1/2],   # r=1\n",
    "        [1/2,   0, 1/2],   # r=2\n",
    "        [1/2, 1/2,   0]]   # r=3\n",
    "\n",
    "# Probabilidad de la pista modelo Monty Hall M1\n",
    "# P(s|r,c,M1) = ps_rcM1[c][r][s] \n",
    "ps_rcM1=[[[  0, 1/2, 1/2],  # r=1, c=1\n",
    "          [  0,   0,   1],  # r=2, c=1\n",
    "          [  0,   1,   0]], # r=3, c=1\n",
    "         [[  ?,   ?,   ?],  # r=1, c=2\n",
    "          [  ?,   ?,   ?],  # r=2, c=2\n",
    "          [  ?,   ?,   ?]], # r=3, c=2\n",
    "         [[  ?,   ?,   ?],  # r=1, c=3\n",
    "          [  ?,   ?,   ?],  # r=2, c=3\n",
    "          [  ?,   ?,   ?]]] # r=3, c=3\n",
    "\n",
    "# Probabilidad del modelo\n",
    "# P(m) = pM[m]\n",
    "pM = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "ocultar"
    ]
   },
   "outputs": [],
   "source": [
    "# Probabilidad del regalo\n",
    "pr = [1/3, 1/3, 1/3] # P(r) = pr[r]\n",
    "\n",
    "# Probabilidad de cerrar\n",
    "pc = [1/3, 1/3, 1/3] # P(c) = pc[c]\n",
    "# Probabilidad de la pista modelo Base M0\n",
    "\n",
    "# P(s|r,M0) = ps_rM0[r][s] \n",
    "ps_rM0=[[  0, 1/2, 1/2],   # r=1\n",
    "        [1/2,   0, 1/2],   # r=2\n",
    "        [1/2, 1/2,   0]]   # r=3\n",
    "# Probabilidad de la pista modelo Monty Hall M1\n",
    "\n",
    "# P(s|r,c,M1) = ps_rcM1[c][r][s] \n",
    "ps_rcM1=[[[  0, 1/2, 1/2],  # r=1, c=1\n",
    "          [  0,   0,   1],  # r=2, c=1\n",
    "          [  0,   1,   0]], # r=3, c=1\n",
    "         [[  0,   0,   1],  # r=1, c=2\n",
    "          [1/2,   0, 1/2],  # r=2, c=2\n",
    "          [  1,   0,   0]], # r=3, c=2\n",
    "         [[  0,   1,   0],  # r=1, c=3\n",
    "          [  1,   0,   0],  # r=2, c=3\n",
    "          [1/2, 1/2,   0]]] # r=3, c=3\n",
    "\n",
    "# Probabilidad del modelo\n",
    "# P(m) = pM[m]\n",
    "pM = [1/2, 1/2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1.1.2**: Simular datos con el modelo Monty Hall\n",
    "\n",
    "Antes de evaluar los modelos necesitamos un conjunto de datos que provengan de la realidad subyacente oculta. Podríamos buscar los datos reales del programa de televisión Monty Hall y revisar si efectivamente el modelo Monty Hall propuesto es mejor que el modelo Base. Para simplificar vamos a suponer que nuestro modelo Monty Hall representa perfectamente la realidad causal subyacente y a generar los datos usando de nuestro propio modelo Monty Hall. Luego, vamos a usar ese conjunto de datos para evaluar los dos modelos. Es de esperar que el modelo que generó los datos tenga mejor desempeño predictivo que el modelo alternativo (en el ejercicio 1.2 veremos que esto no siempre esto es así). Pero también nos interesa ver cuántos datos necesitamos para tener relativa certeza de que la realidad causal subyacente se correponde con el modelo Monty Hall. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# COMPLETAR: Reemplazando signos de pregunta (?)\n",
    "\n",
    "np.random.seed(0) # Para que los números aleatorios sean siempre iguales \n",
    "\n",
    "T = 16 # Cantidad total de episodios\n",
    "Datos = [] # La lista de los datos\n",
    "for t in range(T): # Itero por episodio\n",
    "    # Genero los datos del episodio\n",
    "    r = np.random.choice(3, p=pr)\n",
    "    c = np.random.choice(3, p=pc)\n",
    "    s = np.random.choice( ??? )\n",
    "    Datos.append((c,s,r)) # Agrega el episodio como una tupla (c,s,r)\n",
    "\n",
    "print(Datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "ocultar"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 1), (1, 2, 1), (2, 0, 1), (2, 0, 1), (2, 0, 1), (0, 2, 0), (2, 1, 2), (1, 0, 2), (1, 2, 0), (1, 0, 2), (2, 1, 0), (0, 2, 1), (1, 2, 1), (1, 0, 2), (0, 1, 2), (0, 1, 2)]\n"
     ]
    }
   ],
   "source": [
    "# SOLUCION 1.2 \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "T = 16 # Cantidad total de episodios\n",
    "Datos = [] # La lista de los datos\n",
    "for t in range(T): # Itero por episodio\n",
    "    # Genero los datos \n",
    "    r = np.random.choice(3, p=pr)\n",
    "    c = np.random.choice(3, p=pc)\n",
    "    s = np.random.choice(3, p=ps_rcM1[c][r])\n",
    "    Datos.append((c,s,r)) # Agrega el episodio como una tupla (c,s,r)\n",
    "\n",
    "print(Datos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1.1.3**: Calcular la secuencia de predicción que hacen los modelo de los datos \n",
    "\n",
    "Guardar en las listas `pDatos_M0` y `pDatos_M1` las secuencias de predicciones que hacen cada uno de los modelos sobre la secuencia de episodios. Inicializamos ambas listas con un $1$ (predicción perfecta) en para representar el estado previo a comenzar a predecir los episodios "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# COMPLETAR: Reemplazando signos de pregunta (?)\n",
    "\n",
    "# Inicializacion de la secuencia de predicciones de los modelos\n",
    "pDatos_M0 = [1] # Del modelo 0: No Monty Hall\n",
    "pDatos_M1 = [1] # Del modelo 1: Monty Hall\n",
    "for t in range(T): # Itero sobre episodios\n",
    "    c, s, r = Datos[t]\n",
    "    # Predicciones P(c,s,r|M) \n",
    "    pDatos_M0.append( ??? ) # Dar una única predicción para todo el episodio (número entre 0 y 1)\n",
    "    pDatos_M1.append( ??? ) # Dar una única predicción para todo el episodio (número entre 0 y 1)\n",
    "\n",
    "# Revisar si los resultados son iguales\n",
    "print(pDatos_M0)\n",
    "print(pDatos_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "ocultar"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Datos|M0) = 8.234550899283273e-21\n",
      "P(Datos|M1) = 3.372872048346429e-17\n"
     ]
    }
   ],
   "source": [
    "# OCULTAR\n",
    "\n",
    "# Inicializacion de la secuencia de predicciones de los modelos\n",
    "pDatos_M0 = [1] # Del modelo 0: No Monty Hall\n",
    "pDatos_M1 = [1] # Del modelo 1: Monty Hall\n",
    "for t in range(T): # Itero sobre episodios\n",
    "    c, s, r = Datos[t]\n",
    "    # Predicciones\n",
    "    # P(r,c,s|M) = P(r)P(c)P(s|r,c)\n",
    "    pDatos_M0.append(      pr[r]\n",
    "                         * pc[c]\n",
    "                         * ps_rM0[r][s] )\n",
    "    pDatos_M1.append(      pr[r]\n",
    "                         * pc[c]\n",
    "                         * ps_rcM1[c][r][s] )\n",
    "\n",
    "# Revisar si los resultados son iguales\n",
    "print(\"P(Datos|M0) =\",np.prod(pDatos_M0))\n",
    "print(\"P(Datos|M1) =\",np.prod(pDatos_M1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio 1.1.4**: Expresar intuitivamente la diferencia de desempeño predictivo de los modelos\n",
    "\n",
    "La predicción sobre un conjunto de datos necesariamente resulta ser un número muy cercano a 0. En este caso, en el que observamos tan solo 16 episodios, el modelo Base predijo el conjunto de datos con probabilidad $P(\\text{Datos}|M0) = 8.23e-21$ (con 21 ceros después de la coma) y el modelo Monty Hall predijo con probabilidad $P(\\text{Datos}|M1) = 3.37e-17$ (con 17 ceros después de la coma). Si seguimos agregando episodios al conjunto de datos, este número alcanza valores tan cercanos a cero que deja de ser posible representarlo en una computadora.\n",
    "\n",
    "Existen dos formas alternativas de expresar este número, que son muy útiles además para ganar intuición respecto de la diferencia de desempeño entre modelos. \n",
    "\n",
    "- #### **La predicción expresada en órdenes de magnitud**\n",
    "\n",
    "Expresar la predicción en órdenes de magnitud significa hablar en términos del exponente. Por ejemplo, el exponente de las predicciones del modelo Base es alrededor de $-21$ y el exponente del modelo Monty Hall es alrededor de $-17$, como ya mencionamos anterioramente. La función que nos devuelve el exponente de un número es el `logaritmo`. \n",
    "\n",
    "$$\\underbrace{\\log_{10} P(\\text{Datos}=\\{d_1, d_2, \\dots, d_N \\}|M)}_{\\text{Exponente de la predicción conjunta}} = \\log_{10} (\\underbrace{P(d_1|M) P(d_2|d_1,M) \\dots}_{P(\\text{Datos}|M)}) \\overset{*}{=}  \\underbrace{\\log_{10} P(d_1|M)}_{\\text{Exponente de $d_1$}} + \\underbrace{\\log_{10} P(d_2|d_1,M) }_{\\text{Exponente de $d_2$}} + \\dots  $$\n",
    "\n",
    "El exponente de la predicción conjunta se puede descomponer ($\\overset{*}{=}$) como la suma de los exponentes de las prediciones individuales. Esto permite evitar los problemas de representación computacional. Además, si calculamos la diferencia de exponentes entre los modelos obtendremos la diferencia de desempeño predictivo en órdenes de magnitud, que se conoce como *log Bayes Factor*.\n",
    "\n",
    "$$ \\log_{10} \\underbrace{\\frac{P(\\text{Datos}|M_1)}{P(\\text{Datos}|M_0)}}_{\\text{Bayes factor}}  = \\underbrace{\\log_{10} P(\\text{Datos}|M_1) - \\log_{10}P(\\text{Datos}|M_0)}_{\\text{Diferencia predicitva en ordenes de magnitud}} \\approx (-17) - (-21) = 4$$\n",
    "\n",
    "En base 10, un orden de magnitud significa 10 veces mejor, dos ordenes de magnitud significa 100 veces mejor y cuatro órdenes de magnitud significan 10000. Es decir, al modelo Monty Hall preservó 10000 veces más de creencia previa que el modelo Base. Aunque estos números parezcan extraordinarios, cuatro órdenes de magnitud se considera en el límite de una diferencia no concluytente. Cuando las bases de datos crecen, la diferencia en órdenes de magnitud contiunan creciendo, por lo que es normal ver diferencia de 10000, pero en órdenes de magnitud! En esos casos, para ganar intuición es útil calcular la predicción \"típica\".    \n",
    "\n",
    "- #### **La predicción \"típica\" (o media geométrica)**\n",
    "\n",
    "La media geométrica representa la predicción \"típica\" que hace un modelo de los datos. Decimos que es típica porque podemos reemplazar cada una de las predicciones que componen la secuencia por la media geometrica sin alterar el valor final. Es decir, \n",
    "\n",
    "$$P(\\text{Datos}=\\{d_1, d_2, \\dots, d_N \\}|M) = P(d_1|M) P(d_2|d_1,M) \\dots =  \\prod_{i\\in \\{1,\\dots,N\\}} \\underbrace{(P(d_1|M) P(d_2|d_1,M) \\dots )^{1/N}}_{\\text{Media geométrica}} $$\n",
    "\n",
    "Así expresada, la media geométrica tendría el mismo problema de representación computacional que señalamos al inicio de este ejercicio. Para calcularla hay que hacer algunos pasos intermedios trabajando en órdenes de magnitud.\n",
    "\n",
    "$$ 10^{\\, \\log_{10} (P(d_1|M) P(d_2|d_1,M) \\dots )^{1/N}} = 10^{\\,\\frac{1}{N}\\big(\\log_{10} P(d_1|M) + \\log_{10} P(d_2|d_1,M) + \\dots \\big)}$$\n",
    "\n",
    "La expresión de la derecha puede ser calculada gracias a que es la suma de los exponentes individuales, dividido luego por $N$, la cantidad de datos. En nuestro caso tenemos $T=16$ episodios, pero la cantidad total de datos es $N=T\\cdot3 = 48$, tres por cada episodio. Usaremos este número para calcular la predicción típica. \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferencia de desempeño predictivo expresado en órdenes de magnitud = 3.612359947967775\n",
      "La cantidad creencia que preservó el modelo Monty Hall respecto del modelo Base = 4096.000000000006\n"
     ]
    }
   ],
   "source": [
    "# Las predicciones expresadas en órdenes de magnitud\n",
    "log_evidencia_M0 = np.sum(np.log10(pDatos_M0))\n",
    "log_evidencia_M1 = np.sum(np.log10(pDatos_M1))\n",
    "print(\"Diferencia de desempeño predictivo expresado en órdenes de magnitud =\", log_evidencia_M1-log_evidencia_M0)\n",
    "print(\"La cantidad creencia que preservó el modelo Monty Hall respecto del modelo Base =\", 10**(log_evidencia_M1-log_evidencia_M0))\n",
    "\n",
    "# La predicción típica de los modelos\n",
    "log_evidencia_M0 = np.sum(np.log10(pDatos_M0))\n",
    "log_evidencia_M1 = np.sum(np.log10(pDatos_M1))\n",
    "print(\"Diferencia de desempeño predictivo expresado en órdenes de magnitud =\", log_evidencia_M1-log_evidencia_M0)\n",
    "print(\"La cantidad creencia que preservó el modelo Monty Hall respecto del modelo Base =\", 10**(log_evidencia_M1-log_evidencia_M0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
